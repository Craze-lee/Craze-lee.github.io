<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【Golang进阶】定时器]]></title>
    <url>%2F2019%2F05%2F21%2FGolang%2F%E8%BF%9B%E9%98%B6%2F%E5%AE%9A%E6%97%B6%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Ticker1. 用时间阻塞主程序，从而控制ticker1234567891011121314func main() &#123; // 初始化ticker，每秒执行一次 var ticker = time.NewTicker(1 * time.Second) go func() &#123; for t := range ticker.C &#123; fmt.Println("tick at", t) &#125; &#125;() // 阻塞主程序防退出 time.Sleep(time.Second * 5) // 主动终止 ticker.Stop()&#125; 输出结果 ticker1 at 2019-05-21 14:57:56.562591 +0800 CST m=+1.005065934ticker1 at 2019-05-21 14:57:57.562549 +0800 CST m=+2.005016651ticker1 at 2019-05-21 14:57:58.558122 +0800 CST m=+3.000583914ticker1 at 2019-05-21 14:57:59.563205 +0800 CST m=+4.005660201ticker1 at 2019-05-21 14:58:00.562585 +0800 CST m=+5.005033303 2. 用channel来精准控制次数12345678910111213141516func main() &#123; var ticker2 = time.NewTicker(100 * time.Millisecond) // 创建buffer为2的channel c := make(chan int, 2) go func() &#123; for t := range ticker2.C&#123; // 往channel写数据，写满buffer后终止程序 c &lt;- 1 fmt.Println("ticker2 at ", t) &#125; &#125;() time.Sleep(time.Second * 500) fmt.Println("ticker stopped")&#125; 输出结果 ticker2 at 2019-05-21 14:57:55.65885 +0800 CST m=+0.101330668ticker2 at 2019-05-21 14:57:55.758399 +0800 CST m=+0.200878747]]></content>
      <categories>
        <category>Golang</category>
        <category>进阶</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Golang进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Golang进阶】读写文件]]></title>
    <url>%2F2019%2F05%2F20%2FGolang%2F%E8%BF%9B%E9%98%B6%2F%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"></content>
      <categories>
        <category>Golang</category>
        <category>进阶</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Golang进阶</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F05%2F20%2F%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2%2F%E5%A4%B4%E6%9D%A1%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[# 来自v2ex 1.Redis 常见问题（ 100%）数据结构，与 memcached 的区别，线程，io 多路复用（ select，poll，epoll ）2.zookeeper （ 100%）用法，分布式锁，zab 协议3.MySQL 常见问题（ 100%）存储引擎，锁，隔离级别4.计算机网路（全程抱着电脑边查边问）：tcp 四次挥手（简单的说了下 FIN 和 ACK ）问什么时候关闭连接？ closewait 和 timedwaited 发生在哪里（一开始没说对，在引导下说出） tcp 和 UDP 的区别（ 100%）网络分层每一层具体是什么（我回答没记住只记得最上层应用层，最下层物理层，HTTP→TCP/ UDP→IP ）DNS 是什么（忘了，真忘了😂，我都佩服我自己这忘了）什么是一条连接，如何确定一条连接（ emmm，根据连接 id ？被怼）长连接和短连接的区别（不太了解）]]></content>
  </entry>
  <entry>
    <title><![CDATA[【Golang零基础入门】07 Channel]]></title>
    <url>%2F2019%2F05%2F18%2FGolang%2F%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%2F07%20Channel%2F</url>
    <content type="text"><![CDATA[channel 是goroutine的通道，所以不能直接在非goroutine里直接进行操作，否则会报错，例如 1234c := make(chan int)c &lt;- 1fatal error: all goroutines are asleep - deadlock! var i chan int // 双向channel var i chan&lt;- int // 单向，只能收数据i &lt;- 1 // 这是允许的j &lt;- i // 这是不允许的 var i &lt;-chan int // 单向，只能发数据 buffer channelbuffer可以减少goroutine的切换，例如下面，创建了3buffer的channel，在往channel写数据时，前3个写入都是会存储到buffer，但是写第4个的时候，会发现报错，fatal error: all goroutines are asleep - deadlock!，因为buffer已满，没有goroutine处理该channel数据。所以如果是没有buffer的channel，每次写入都会有一次goroutine的切换。 1234567func bufferChannel() &#123; c := make(chan int, 3) // 创建带有3 buffer的channel c &lt;- 'a' c &lt;- 'b' c &lt;- 'c' //c &lt;- 'd' // 取消注释后会报错，因为没有接受处理channel的方法&#125; channel close1234567891011121314func worker(c chan int) &#123; for n := range c &#123; fmt.Printf("received %c\n", n) &#125;&#125;func closeDemo() &#123; c := make(chan int, 3) go worker(c) c &lt;- 'a' c &lt;- 'b' c &lt;- 'c' close(c) // 主动关闭channel，如果不主动关闭，goroutine会一直收数据&#125; 不要通过共享内存来通信，通过通信来共享内存 这篇文章里面说的比较清楚了，使用共享内存的话在多线程的场景下为了处理竞态，需要加锁，使用起来比较麻烦。另外使用过多的锁，容易使得程序的代码逻辑坚涩难懂，并且容易使程序死锁，死锁了以后排查问题相当困难，特别是很多锁同时存在的时候。 go语言的channel保证同一个时间只有一个goroutine能够访问里面的数据，为开发者提供了一种优雅简单的工具，所以go原生的做法就是使用channle来通信，而不是使用共享内存来通信。 http://legendtkl.com/2017/07/30/understanding-golang-channel/]]></content>
      <categories>
        <category>Golang</category>
        <category>零基础入门</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Golang零基础入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【PHP】垃圾回收GC]]></title>
    <url>%2F2019%2F05%2F16%2Fphp%2F%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6GC%2F</url>
    <content type="text"><![CDATA[垃圾回收是什么写了这么多年的PHP，你还不知道它的垃圾回收机制？不怕自己被回收了吗？ 我觉得你得有匠(降)心(薪)精神啊。]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【MySQL 原理】02 索引原理与实现（一）]]></title>
    <url>%2F2019%2F05%2F14%2FMySQL%2FMySQL%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[前言 讲到索引，第一反应肯定是能提高查询效率。例如书的目录，想要查找某一章节，会先从目录中定位。如果没有目录，那么就需要将所有内容都看一遍才能找到。 索引的设计对程序的性能至关重要，若索引太少，对查询性能受影响；而如果索引太多，则会影响增/改/删等的性能。 知识点MySQL中一般支持以下几种常见的索引： B+树索引 全文索引 哈希索引 我们今天重点来讲下B+树索引，以及为什么要用B+树来作为索引的数据结构。 B+树索引并不能直接找到具体的行，只是找到被查找行所在的页，然后DB通过把整页读入内存，再在内存中查找。 重温数据结构1.1 哈希结构如有 3、1、2、10、9、0、4、6这8个数据，建立如图1-1所示哈希索引。 直接查询：现在要从8个数中查找6这条记录，只需要计算6的哈希值，便可快速定位记录，时间复杂度为O(1)。 范围查询：如果要进行范围查询（大于4的数据），那这个索引就完全没用了。 图1-1 哈希索引 1.2 二叉树查找树二叉树是一种经典的数据结构，要求左子树小于根节点，右子树大于根节点。 如有 3、1、2、10、9、0、4、6这8个数据，建立如图1-2所示二分查找树。 直接查询：假设查找键值为6的记录，先找到根4，4&lt;6，因此查找4的右子树，找到9；9大于6，因此查找9的左子树；一共查找3次。但如果顺序查找，则需要查找8次（位于最后）。 范围查询：如果需要查找大于4的数据，则遍历4的右子树就行了。 图1-2 二叉查找树 1.3 平衡二叉树（AVL树）按照二叉查找树的定义，它是可以任意的构造，同样是这些数字，可以按照图1-3-1的方式来建立二叉查找树。同样查找数据6，需要查找5次。 图1-3-1 性能较差的二叉查找树 因此为了最大性能地构造一个二叉查找树，需要它是平衡的，即平衡二叉树。 平衡二叉树定义：首先符合二叉查找树的定义，另外任何节点的两个子树高度最大差为1。 平衡二叉树的查询速度是很快的，但是有缺点： 维护树的代价是非常大，在进行插入或更新时，经常会需要多次左旋或右旋来维持平衡。如图1-3-2所示 数据量多的时候，树会很高，需要多次I/O操作。 在进行范围查找时，假设查找&gt;=3，先找到3，然后需要查找到3的父节点，然后遍历父节点的右子树。 图1-3-2 平衡二叉树AVL 1.4 B+ 树在B+树中，所有记录节点存放在叶子节点上，且是顺序存放，由各叶子节点指针进行连接。如果从最左边的叶子节点开始顺序遍历，能得到所有键值的顺序排序。 如有 3、1、2、10、9、0、4、6这8个数据，可建立如图1-4-1所示高度为2的B+树。 图1-4-1 高度为2的B+树 在进行更新时，B+树同样需要类似二叉树的旋转操作。举例，假设新增一个7，那可以直接填充到4、6的后面。如果再添加8，那么就需要进行旋转了，感受下面的B+树旋转过程。 图1-4-2 高度为3的B+树 采用B+树的索引结构优点： B+树的高度一般为2-4层，所以查找记录时最多只需要2-4次IO，相对二叉平衡树已经大大降低了。 范围查找时，能通过叶子节点的指针获取数据。例如查找大于等于3的数据，当在叶子节点中查到3时，通过3的尾指针便能获取所有数据，而不需要再像二叉树一样再获取到3的父节点。 看到这应该明白mysql索引为什么使用B+树了吧！！！ 未完待续…]]></content>
      <categories>
        <category>MySQL</category>
        <category>原理分析</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>原理分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Golang进阶】flag 命令行包使用]]></title>
    <url>%2F2019%2F05%2F06%2FGolang%2F%E8%BF%9B%E9%98%B6%2Fflag%E5%8C%85%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Package flagimport “flag” flag 包实现命令行标签解析. 简单Demo123456789101112131415package mainimport ( "flag" "fmt")var num = flag.Int("num", 1234, "Input your ip")var config = flag.String("config", "default.conf", "Input your config file path")func main() &#123; flag.Parse() fmt.Println("ip has value ", *num) fmt.Println("config file path ", *config)&#125; 像Linux命令行一样查看帮助 执行时不带参数，使用默认值 执行时赋值参数 使用说明： 定义标签 1234567891011// 定义interger标签var num = flag.Int("num", 1234, "Input your ip")// 定义string标签var config = flag.String("config", "default.conf", "Input your config file path")// Var()函数将标签绑定到指定变量中var flagvar intfunc InitFlag() &#123; flag.IntVar(&amp;flagvar, "flagvar", 1234, "Input your flagvar name")&#125; 解析参数 1flag.Parse() 使用标签 12fmt.Println(&quot;ip has value &quot;, *num)fmt.Println(&quot;config file path &quot;, *config) 经验在开发的时候，很多时候会有多个环境，基本会以这种方式去加载对应环境的配置文件 参考：https://godoc.org/flag]]></content>
      <categories>
        <category>Golang</category>
        <category>进阶</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Golang进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gopher China 2016]]></title>
    <url>%2F2019%2F05%2F04%2FGolang%2FGopher%E5%88%86%E4%BA%AB%2FGopher%20China%202016%2F</url>
    <content type="text"><![CDATA[Why Gogofmt 团队代码风格一致强类型语言，任何严肃的项目都不应该用弱类型语言import 很好的开源协同开发profile 能力强大build standalone binary 简单部署goroutines 提供天然的并发编程微服务最好的语言：native web框架、gRPC、docker GC 优化思路Mark and Sweep: 大量时间用于扫描对象 常规手段的核心：减少对象]]></content>
      <categories>
        <category>Golang</category>
        <category>Gopher</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Gopher</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gopher China 大会视频]]></title>
    <url>%2F2019%2F05%2F04%2FGolang%2FGopher%E5%88%86%E4%BA%AB%2FGopherChina%E5%A4%A7%E4%BC%9A%E8%A7%86%E9%A2%91%E5%A4%A7%E5%85%A8%2F</url>
    <content type="text"><![CDATA[https://segmentfault.com/a/1190000018560530]]></content>
      <categories>
        <category>Golang</category>
        <category>Gopher</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Gopher</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Golang零基础入门】06 Goroutine]]></title>
    <url>%2F2019%2F04%2F20%2FGolang%2F%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%2F06%20Goroutine%2F</url>
    <content type="text"><![CDATA[引言现在很多一线大厂都转型到Go，究其原因就是该语言对并发支持的好。相信大家都知道Golang是在语言级原生支持协程，先看看下面这段代码 1234567891011func main() &#123; for i:=0; i&lt;10; i++ &#123; go func(i int) &#123; for &#123; fmt.Printf("协程: %d \n", i) &#125; &#125;(i) &#125; // 防止程序来不及打印就退出 time.Sleep(10*time.Microsecond)&#125; 输出结果如下，你会发现每次运行，输出内容都是不一样的，这是为什么呢？ 一、并行与并发并行是指程序的运行状态，要有两个线程正在执行才能算是Parallelism； 并发指程序的逻辑结构，Concurrency则只要有两个以上线程还在执行过程中即可。 简单地说，Parallelism要在多核或者多处理器情况下才能做到，而Concurrency则不需要。对应后面的runtime.GOMAXPROCS(runtime.NumCPU()) 二、进程，线程与协程goroutines是Go的并发基础，为了帮助我们理解这个概念，我们先来谈一谈并发的发展故事。 2.1 进程 Process进程是程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是线程的容器。 在分时系统中，操作系统通过记录当前进程的状态，然后恢复另一个进程的状态，在活动进程之间快速切换CPU的处理，而产生了一种并发执行的错觉，这个过程称为上下文切换(switch cost)。 上下文切换的成本是： 内核需要存储该进程的所有CPU寄存器的内容，然后恢复另一个进程的值。由于进程切换可以在进程执行的任何时刻发生，操作系统需要存储所有这些寄存器的内容，因为它不知道当前正在使用哪些寄存器。 内核需要将CPU的虚拟地址刷新为物理地址映射（TLB缓存）。 操作系统上下文切换的开销，以及选择下一个进程都会占用CPU的调度程序函数的开销。 2.2 线程 thread线程是操作系统能够进行运算调度的最小单位，在概念上与进程类似，但共享相同的内存空间。由于线程共享地址空间，因此创建、切换速度更快。但仍然有昂贵的上下文切换成本; 必须保留很多状态。 2.3 协程 Coroutine协程是用户态线程，不依靠内核来管理调度，具备以下特点： 轻量级线程 非抢占式多任务处理，由协程自己本省主动交出控制权 以下列出了goroutine之间切换的主要的时间点： （1）Channel发送和接收操作（如果这些操作是阻塞的）；（2）执行go语句，虽然不能保证新的goroutine马上被调度执行；（3）阻塞的系统调用，像文件操作，网络操作，IO等等；（4）停下来进入垃圾回收周期以后。 换句话讲，在goroutine不能继续进行运算以后（需要更多数据，更多空间，等等），都会进行切换。 双向通道就是channel GO的协程 Goroutines每个并发的执行单元叫做goroutine，用关键词go来创建。具体goroutine放在哪个线程，由调度器控制与切换。 假设要计算两个非常复杂的逻辑，然后输出结果。在正常是线性程序里面，会依次调用计算的逻辑，完成之后再调用输出逻辑。但如果是在有两个甚至更多个goroutine的程序中，对两个计算逻辑的调用就可以在同一时间。 1234567891011121314151617181920func main() &#123; var wg sync.WaitGroup wg.Add(2) go func() &#123; for i:=0; i&lt;100; i++ &#123; defer wg.Done() fmt.Println("A:", i) time.Sleep(1*time.Second) &#125; &#125;() go func() &#123; for i:=0; i&lt;100; i++ &#123; defer wg.Done() fmt.Println("B:", i) time.Sleep(2*time.Second) &#125; &#125;() wg.Wait()&#125; 我们运行这个程序，会发现A和B前缀会交叉出现，即两个程序是并发在执行的，并且每次运行的结果可能不一样，这就是Go调度器调度的结果。 这里的sync.WaitGroup其实是一个计数的信号量，使用它的目的是要main函数等待两个goroutine执行完成后再结束，不然这两个goroutine还在运行的时候，程序就结束了，看不到想要的结果。 sync.WaitGroup的使用也非常简单，先是使用Add 方法设设置计算器为2，每一个goroutine的函数执行完之后，就调用Done方法减1。Wait方法的意思是如果计数器大于0，就会阻塞，所以main 函数会一直等待2个goroutine完成后，再结束。 对于逻辑处理器的个数，不是越多越好，要根据电脑的实际物理核数，如果不是多核的，设置再多的逻辑处理器个数也没用，如果需要设置的话，一般我们采用如下代码设置。 1runtime.GOMAXPROCS(runtime.NumCPU()) 所以对于并发来说，就是Go语言本身自己实现的调度，对于并行来说，是和运行的电脑的物理处理器的核数有关的，多核就可以并行并发，单核只能并发了。]]></content>
      <categories>
        <category>Golang</category>
        <category>零基础入门</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Golang零基础入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elastic Search 分布式特性]]></title>
    <url>%2F2019%2F04%2F12%2FElasticSearch%2FES%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%2F</url>
    <content type="text"><![CDATA[当索引一个文档的时候，文档会被存储到一个主分片中。 路由公式： shard = hash(routing) % number_of_primary_shards 主分片和副分片交互 可以发送请求到集群中的任一节点。 每个节点都有能力处理任意请求。 每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。 当发送请求的时候， 为了扩展负载，更好的做法是轮询集群中所有的节点。 新建、索引和删除单个文档 以下是在主副分片和任何副本分片上面 成功新建，索引和删除文档所需要的步骤顺序： 客户端向 Node 1 发送新建、索引或者删除请求。节点使用文档的 _id 确定文档属于分片 0 。请求会被转发到 Node 3，因为分片 0 的主分片目前被分配在Node 3 上。Node 3 在主分片上面执行请求。如果成功了，它将请求并行转发到 Node 1 和 Node 2 的副本分片上。一旦所有的副本分片都报告成功, Node 3 将向协调节点报告成功，协调节点向客户端报告成功。 读取文档以下是从主分片或者副本分片检索文档的步骤顺序： 1、客户端向 Node 1 发送获取请求。 2、节点使用文档的 _id 来确定文档属于分片 0 。分片 0 的副本分片存在于所有的三个节点上。 在这种情况下，它将请求转发到 Node 2 。 3、Node 2 将文档返回给 Node 1 ，然后将文档返回给客户端。 在处理读取请求时，协调结点在每次请求的时候都会通过轮询所有的副本分片来达到负载均衡。 mget读取多个文档 以下是使用单个 mget 请求取回多个文档所需的步骤顺序：客户端向 Node 1 发送 mget 请求。Node 1 为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复， Node 1 构建响应并将其返回给客户端。 使用 bulk 修改多个文档 bulk API 按如下步骤顺序执行： 客户端向 Node 1 发送 bulk 请求。Node 1 为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。 一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。bulk API 还可以在整个批量请求的最顶层使用 consistency 参数，以及在每个请求中的元数据中使用 routing 参数。]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elastic Search 分布式特性]]></title>
    <url>%2F2019%2F04%2F11%2FElasticSearch%2FES%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA%2F</url>
    <content type="text"><![CDATA[在 Elasticsearch 中， 每个字段的所有数据 都是 默认被索引的 。 即每个字段都有为了快速检索设置的专用倒排索引。而且，不像其他多数的数据库，它能在 同一个查询中 使用所有这些倒排索引，并以惊人的速度返回结果。 文档 一个对象仅仅是类似于 hash 、 hashmap 、字典或者关联数组的 JSON 对象，对象中也可以嵌套其他的对象。 对象可能包含了另外一些对象。 在 Elasticsearch 中，术语 文档 有着特定的含义。它是指最顶层或者根对象, 这个根对象被序列化成 JSON 并存储到 Elasticsearch 中，指定了唯一 ID。 文档元数据_index：一个 索引 应该是因共同的特性被分组到一起的文档集合。类比数据库_type：在索引中对数据进行逻辑分区。类比数据表_id：当它和 _index 以及 _type 组合就可以唯一确定 Elasticsearch 中的一个文档。类比数据唯一标识 写数据 12345678910111213141516171819202122232425262728PUT /&#123;index&#125;/&#123;type&#125;/&#123;id&#125;&#123; &quot;field&quot;: &quot;value&quot;, ...&#125;# For Example curl -X PUT &quot;10.96.83.188:9200/website/blog/123&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;title&quot;: &quot;My first blog entry&quot;, &quot;text&quot;: &quot;Just trying this out...&quot;, &quot;date&quot;: &quot;2014/01/01&quot;&#125;&apos;&#123;&quot;_index&quot;:&quot;website&quot;,&quot;_type&quot;:&quot;blog&quot;,&quot;_id&quot;:&quot;123&quot;,&quot;_version&quot;:1,&quot;result&quot;:&quot;created&quot;,&quot;_shards&quot;:&#123;&quot;total&quot;:2,&quot;successful&quot;:1,&quot;failed&quot;:0&#125;,&quot;created&quot;:true&#125;# 如果没有指定ID，Elasticsearch 可以帮我们自动生成 ID curl -X POST &quot;10.96.83.188:9200/website/blog/&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;title&quot;: &quot;My second blog entry&quot;, &quot;text&quot;: &quot;Still trying this out...&quot;, &quot;date&quot;: &quot;2014/01/01&quot;&#125;&apos;&#123;&quot;_index&quot;:&quot;website&quot;,&quot;_type&quot;:&quot;blog&quot;,&quot;_id&quot;:&quot;AWoPmj2eBvBN4YG5RXks&quot;,&quot;_version&quot;:1,&quot;result&quot;:&quot;created&quot;,&quot;_shards&quot;:&#123;&quot;total&quot;:2,&quot;successful&quot;:1,&quot;failed&quot;:0&#125;,&quot;created&quot;:true&#125; 读数据pretty 为了让输出更友好 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#取所有字段curl -X GET &quot;10.96.83.188:9200/website/blog/123?pretty&quot;&#123; &quot;_index&quot; : &quot;website&quot;, &quot;_type&quot; : &quot;blog&quot;, &quot;_id&quot; : &quot;123&quot;, &quot;_version&quot; : 1, &quot;found&quot; : true, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;My first blog entry&quot;, &quot;text&quot; : &quot;Just trying this out...&quot;, &quot;date&quot; : &quot;2014/01/01&quot; &#125;&#125;# 取部分字段curl -X GET &quot;10.96.83.188:9200/website/blog/123?_source=title,text&amp;pretty&quot;&#123; &quot;_index&quot; : &quot;website&quot;, &quot;_type&quot; : &quot;blog&quot;, &quot;_id&quot; : &quot;123&quot;, &quot;_version&quot; : 1, &quot;found&quot; : true, &quot;_source&quot; : &#123; &quot;text&quot; : &quot;Just trying this out...&quot;, &quot;title&quot; : &quot;My first blog entry&quot; &#125;&#125;# 只取数据，不去元数据 curl -X GET &quot;10.96.83.188:9200/website/blog/123/_source&quot;&#123; &quot;title&quot;: &quot;My first blog entry&quot;, &quot;text&quot;: &quot;Just trying this out...&quot;, &quot;date&quot;: &quot;2014/01/01&quot;&#125;# 读取多个数据curl -X GET &quot;10.96.83.188:9200/_mget?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;docs&quot; : [ &#123; &quot;_index&quot; : &quot;website&quot;, &quot;_type&quot; : &quot;blog&quot;, &quot;_id&quot; : 1 &#125;, &#123; &quot;_index&quot; : &quot;website&quot;, &quot;_type&quot; : &quot;blog&quot;, &quot;_id&quot; : 124 &#125; ]&#125;&apos; 判断文档是否存在(200存在，404不存在) 123456789$ curl -I -XHEAD &quot;10.96.83.188:9200/website/blog/123/&quot;HTTP/1.1 200 OKcontent-type: text/plain; charset=UTF-8content-length: 0$ curl -I -XHEAD &quot;10.96.83.188:9200/website/blog/124/&quot;HTTP/1.1 404 Not Foundcontent-type: text/plain; charset=UTF-8content-length: 0 更新操作 创建新文档 要么id保证唯一，要么不带id新建，由ES自动创建创建时，带上_create，保证只新增，如果已存在则报错 123456789curl -X PUT &quot;10.96.83.188:9200/website/blog/123/_create&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;title&quot;: &quot;My first blog entry&quot;, &quot;text&quot;: &quot;I am starting to get the hang of this...&quot;, &quot;date&quot;: &quot;2014/01/02&quot;&#125;&apos;&#123;&quot;error&quot;:&#123;&quot;root_cause&quot;:[&#123;&quot;type&quot;:&quot;version_conflict_engine_exception&quot;,&quot;reason&quot;:&quot;[blog][123]: version conflict, document already exists (current version [2])&quot;,&quot;index_uuid&quot;:&quot;_sBTT-DdSnKytaOhbXEYfw&quot;,&quot;shard&quot;:&quot;0&quot;,&quot;index&quot;:&quot;website&quot;&#125;],&quot;type&quot;:&quot;version_conflict_engine_exception&quot;,&quot;reason&quot;:&quot;[blog][123]: version conflict, document already exists (current version [2])&quot;,&quot;index_uuid&quot;:&quot;_sBTT-DdSnKytaOhbXEYfw&quot;,&quot;shard&quot;:&quot;0&quot;,&quot;index&quot;:&quot;website&quot;&#125;,&quot;status&quot;:409&#125; 删除文档 12curl -X DELETE &quot;10.96.83.188:9200/website/blog/123&quot;&#123;&quot;found&quot;:true,&quot;_index&quot;:&quot;website&quot;,&quot;_type&quot;:&quot;blog&quot;,&quot;_id&quot;:&quot;123&quot;,&quot;_version&quot;:3,&quot;result&quot;:&quot;deleted&quot;,&quot;_shards&quot;:&#123;&quot;total&quot;:2,&quot;successful&quot;:1,&quot;failed&quot;:0&#125;&#125; 更新部分文档 12345678910111213141516171819202122232425curl -X POST &quot;10.96.83.188:9200/website/blog/1/_update&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;doc&quot; : &#123; &quot;tags&quot; : [ &quot;testing&quot; ], &quot;views&quot;: 0 &#125;&#125;&apos;curl -X GET &quot;10.96.83.188:9200/website/blog/1?pretty&quot;&#123; &quot;_index&quot; : &quot;website&quot;, &quot;_type&quot; : &quot;blog&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 3, &quot;found&quot; : true, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;My first blog entry&quot;, &quot;text&quot; : &quot;Starting to get the hang of this...&quot;, &quot;views&quot; : 0, &quot;tags&quot; : [ &quot;testing&quot; ] &#125;&#125; 乐观并发控制]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elastic Search 分布式特性]]></title>
    <url>%2F2019%2F04%2F11%2FElasticSearch%2FES%E5%88%86%E5%B8%83%E5%BC%8F%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[Elasticsearch 可以横向扩展至数百（甚至数千）的服务器节点，同时可以处理PB级数据。Elasticsearch 天生就是分布式的，并且在设计时屏蔽了分布式的复杂性。这里列举了一些在后台自动执行的操作： 分配文档到不同的容器 或 分片 中，文档可以储存在一个或多个节点中 按集群节点来均衡分配这些分片，从而对索引和搜索过程进行负载均衡 复制每个分片以支持数据冗余，从而防止硬件故障导致的数据丢失 将集群中任一节点的请求路由到存有相关数据的节点 集群扩容时无缝整合新节点，重新分配分片以便从离群节点恢复 Elasticsearch 是利用分片将数据分发到集群内各处的。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里。 当你的集群规模扩大或者缩小时， Elasticsearch 会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里。 一个分片可以是 主 分片或者 副本 分片。 索引内任意一个文档都归属于一个主分片，所以主分片的数目决定着索引能够保存的最大数据量。 一个副本分片只是一个主分片的拷贝。 副本分片作为硬件故障时保护数据不丢失的冗余备份，并为搜索和返回文档等读操作提供服务。 扩容主分片的数目在索引创建时 就已经确定了下来。实际上，这个数目定义了这个索引能够 存储 的最大数据量。但是，读操作——搜索和返回数据——可以同时被主分片 或 副本分片所处理，所以当你拥有越多的副本分片时，也将拥有越高的吞吐量。 当然，如果只是在相同节点数目的集群上增加更多的副本分片并不能提高性能，因为每个分片从节点上获得的资源会变少。 你需要增加更多的硬件资源来提升吞吐量。 故障 关闭的节点是一个主节点。而集群必须拥有一个主节点来保证正常工作，所以发生的第一件事情就是选举一个新的主节点： Node 2 。新的主节点立即将这些分片在 Node 2 和 Node 3 上对应的副本分片提升为主分片， 此时集群的状态将会为 yellow 。 这个提升主分片的过程是瞬间发生的，如同按下一个开关一般。]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elastic Search 基础介绍]]></title>
    <url>%2F2019%2F04%2F11%2FElasticSearch%2FES%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[ElasticSearch 是一个分布式、可扩展、实时的搜索与数据分析引擎。 功能介绍 全文搜索 结构化数据的实时统计 数据分析 复杂的语言处理 地理位置和对象间关联关系 应用场景 Wikipedia 使用 Elasticsearch 提供带有高亮片段的全文搜索 Stack Overflow 将地理位置查询融入全文检索中去，并且使用 more-like-this 接口去查找相关的问题与答案 GitHub 使用 Elasticsearch 对1300亿行代码进行查询 特点 一个分布式的实时文档存储，每个字段 可以被索引与搜索 一个分布式实时分析搜索引擎 能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据 操作索引结构分析路径 /megacorp/employee/1 包含了三部分的信息： megacorp：索引名称，类似数据库employee：类型名称，类似数据表1：特定雇员的ID，类似表里的ID 写入 123456789curl -X PUT &quot;localhost:9200/megacorp/employee/1&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;first_name&quot; : &quot;John&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 25, &quot;about&quot; : &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]&#125;&apos; 查询 12345678910curl &apos;localhost:9200/megacorp/employee/1?pretty&apos;&#123;&quot;_index&quot;:&quot;megacorp&quot;,&quot;_type&quot;:&quot;employee&quot;,&quot;_id&quot;:&quot;2&quot;,&quot;_version&quot;:1,&quot;found&quot;:true,&quot;_source&quot;:&#123; &quot;first_name&quot; : &quot;John&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 25, &quot;about&quot; : &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]&#125;&#125; 搜索 1234567891011121314151617181920212223242526curl -X GET &quot;10.96.83.188:9200/megacorp/employee/_search&quot;&#123;&quot;took&quot;:71,&quot;timed_out&quot;:false,&quot;_shards&quot;:&#123;&quot;total&quot;:5,&quot;successful&quot;:5,&quot;failed&quot;:0&#125;,&quot;hits&quot;:&#123;&quot;total&quot;:3,&quot;max_score&quot;:1.0,&quot;hits&quot;:[&#123;&quot;_index&quot;:&quot;megacorp&quot;,&quot;_type&quot;:&quot;employee&quot;,&quot;_id&quot;:&quot;2&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:&#123; &quot;first_name&quot; : &quot;Jane&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 32, &quot;about&quot; : &quot;I like to collect rock albums&quot;, &quot;interests&quot;: [ &quot;music&quot; ]&#125;&#125;,&#123;&quot;_index&quot;:&quot;megacorp&quot;,&quot;_type&quot;:&quot;employee&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:&#123; &quot;first_name&quot; : &quot;John&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 25, &quot;about&quot; : &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]&#125;&#125;,&#123;&quot;_index&quot;:&quot;megacorp&quot;,&quot;_type&quot;:&quot;employee&quot;,&quot;_id&quot;:&quot;3&quot;,&quot;_score&quot;:1.0,&quot;_source&quot;:&#123; &quot;first_name&quot; : &quot;Douglas&quot;, &quot;last_name&quot; : &quot;Fir&quot;, &quot;age&quot; : 35, &quot;about&quot;: &quot;I like to build cabinets&quot;, &quot;interests&quot;: [ &quot;forestry&quot; ]&#125;&#125;]&#125;&#125; 简单查询 query_string 123456789101112131415161718curl -X GET &quot;10.96.83.188:9200/megacorp/employee/_search?q=last_name:Smith&quot;&#123;&quot;took&quot;:31,&quot;timed_out&quot;:false,&quot;_shards&quot;:&#123;&quot;total&quot;:5,&quot;successful&quot;:5,&quot;failed&quot;:0&#125;,&quot;hits&quot;:&#123;&quot;total&quot;:2,&quot;max_score&quot;:0.2876821,&quot;hits&quot;:[&#123;&quot;_index&quot;:&quot;megacorp&quot;,&quot;_type&quot;:&quot;employee&quot;,&quot;_id&quot;:&quot;2&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123; &quot;first_name&quot; : &quot;Jane&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 32, &quot;about&quot; : &quot;I like to collect rock albums&quot;, &quot;interests&quot;: [ &quot;music&quot; ]&#125;&#125;,&#123;&quot;_index&quot;:&quot;megacorp&quot;,&quot;_type&quot;:&quot;employee&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123; &quot;first_name&quot; : &quot;John&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 25, &quot;about&quot; : &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]&#125;&#125;]&#125;&#125; 查询表达式搜索 query 123456789101112131415161718192021222324252627curl -X GET &quot;10.96.83.188:9200/megacorp/employee/_search&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;last_name&quot; : &quot;Smith&quot; &#125; &#125;&#125;&apos;&#123;&quot;took&quot;:9,&quot;timed_out&quot;:false,&quot;_shards&quot;:&#123;&quot;total&quot;:5,&quot;successful&quot;:5,&quot;failed&quot;:0&#125;,&quot;hits&quot;:&#123;&quot;total&quot;:2,&quot;max_score&quot;:0.2876821,&quot;hits&quot;:[&#123;&quot;_index&quot;:&quot;megacorp&quot;,&quot;_type&quot;:&quot;employee&quot;,&quot;_id&quot;:&quot;2&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123; &quot;first_name&quot; : &quot;Jane&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 32, &quot;about&quot; : &quot;I like to collect rock albums&quot;, &quot;interests&quot;: [ &quot;music&quot; ]&#125;&#125;,&#123;&quot;_index&quot;:&quot;megacorp&quot;,&quot;_type&quot;:&quot;employee&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123; &quot;first_name&quot; : &quot;John&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 25, &quot;about&quot; : &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]&#125;&#125;]&#125;&#125; 更复杂的搜索 过滤器 filter 123456789101112131415161718192021222324252627curl -X GET &quot;10.96.83.188:9200/megacorp/employee/_search&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;query&quot; : &#123; &quot;bool&quot;: &#123; &quot;must&quot;: &#123; &quot;match&quot; : &#123; &quot;last_name&quot; : &quot;smith&quot; &#125; &#125;, &quot;filter&quot;: &#123; &quot;range&quot; : &#123; &quot;age&quot; : &#123; &quot;gt&quot; : 30 &#125; &#125; &#125; &#125; &#125;&#125;&apos;&#123;&quot;took&quot;:15,&quot;timed_out&quot;:false,&quot;_shards&quot;:&#123;&quot;total&quot;:5,&quot;successful&quot;:5,&quot;failed&quot;:0&#125;,&quot;hits&quot;:&#123;&quot;total&quot;:1,&quot;max_score&quot;:0.2876821,&quot;hits&quot;:[&#123;&quot;_index&quot;:&quot;megacorp&quot;,&quot;_type&quot;:&quot;employee&quot;,&quot;_id&quot;:&quot;2&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123; &quot;first_name&quot; : &quot;Jane&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 32, &quot;about&quot; : &quot;I like to collect rock albums&quot;, &quot;interests&quot;: [ &quot;music&quot; ]&#125;&#125;]&#125;&#125; 全文搜索 1234567891011121314151617181920212223242526curl -X GET &quot;10.96.83.188:9200/megacorp/employee/_search&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;about&quot; : &quot;rock climbing&quot; &#125; &#125;&#125;&apos;&#123;&quot;took&quot;:8,&quot;timed_out&quot;:false,&quot;_shards&quot;:&#123;&quot;total&quot;:5,&quot;successful&quot;:5,&quot;failed&quot;:0&#125;,&quot;hits&quot;:&#123;&quot;total&quot;:2,&quot;max_score&quot;:0.53484553,&quot;hits&quot;:[&#123;&quot;_index&quot;:&quot;megacorp&quot;,&quot;_type&quot;:&quot;employee&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_score&quot;:0.53484553,&quot;_source&quot;:&#123; &quot;first_name&quot; : &quot;John&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 25, &quot;about&quot; : &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]&#125;&#125;,&#123;&quot;_index&quot;:&quot;megacorp&quot;,&quot;_type&quot;:&quot;employee&quot;,&quot;_id&quot;:&quot;2&quot;,&quot;_score&quot;:0.26742277,&quot;_source&quot;:&#123; &quot;first_name&quot; : &quot;Jane&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 32, &quot;about&quot; : &quot;I like to collect rock albums&quot;, &quot;interests&quot;: [ &quot;music&quot; ]&#125;&#125;]&#125;&#125; Elasticsearch 默认按照相关性得分排序，即每个文档跟查询的匹配程度。第一个最高得分的结果很明显：John Smith 的 about 属性清楚地写着 “rock climbing”Jane Smith也作为结果返回，原因是她的 about 属性里提到了 “rock” 。因为只有 “rock” 而没有 “climbing” ，所以她的相关性得分低于 John 的。 这是完全区别于传统关系型数据库的一个概念，数据库中的一条记录要么匹配要么不匹配。 短语搜索 想要精确匹配一系列单词或者短语。匹配同时包含 “rock” 和 “climbing” ，并且 二者以短语 “rock climbing” 的形式紧挨着的雇员记录。为此对 match 查询稍作调整，使用一个叫做 match_phrase 的查询 123456789101112131415161718 curl -X GET &quot;10.96.83.188:9200/megacorp/employee/_search&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;query&quot; : &#123; &quot;match_phrase&quot; : &#123; &quot;about&quot; : &quot;rock climbing&quot; &#125; &#125;&#125;&apos;&#123;&quot;took&quot;:13,&quot;timed_out&quot;:false,&quot;_shards&quot;:&#123;&quot;total&quot;:5,&quot;successful&quot;:5,&quot;failed&quot;:0&#125;,&quot;hits&quot;:&#123;&quot;total&quot;:1,&quot;max_score&quot;:0.53484553,&quot;hits&quot;:[&#123;&quot;_index&quot;:&quot;megacorp&quot;,&quot;_type&quot;:&quot;employee&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_score&quot;:0.53484553,&quot;_source&quot;:&#123; &quot;first_name&quot; : &quot;John&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 25, &quot;about&quot; : &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]&#125;&#125;]&#125;&#125; 高亮搜索 返回结果与之前一样，与此同时结果中还多了一个叫做 highlight 的部分。这个部分包含了 about 属性匹配的文本片段，并以 HTML 标签 封装 1234567891011121314151617181920212223curl -X GET &quot;10.96.83.188:9200/megacorp/employee/_search&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;query&quot; : &#123; &quot;match_phrase&quot; : &#123; &quot;about&quot; : &quot;rock climbing&quot; &#125; &#125;, &quot;highlight&quot;: &#123; &quot;fields&quot; : &#123; &quot;about&quot; : &#123;&#125; &#125; &#125;&#125;&apos;&#123;&quot;took&quot;:36,&quot;timed_out&quot;:false,&quot;_shards&quot;:&#123;&quot;total&quot;:5,&quot;successful&quot;:5,&quot;failed&quot;:0&#125;,&quot;hits&quot;:&#123;&quot;total&quot;:1,&quot;max_score&quot;:0.53484553,&quot;hits&quot;:[&#123;&quot;_index&quot;:&quot;megacorp&quot;,&quot;_type&quot;:&quot;employee&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_score&quot;:0.53484553,&quot;_source&quot;:&#123; &quot;first_name&quot; : &quot;John&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 25, &quot;about&quot; : &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]&#125;,&quot;highlight&quot;:&#123;&quot;about&quot;:[&quot;I love to go &lt;em&gt;rock&lt;/em&gt; &lt;em&gt;climbing&lt;/em&gt;&quot;]&#125;&#125;]&#125;&#125; 分析 123456789101112131415161718192021222324252627282930313233curl -X GET &quot;10.96.83.188:9200/megacorp/employee/_search&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;aggs&quot;: &#123; &quot;all_interests&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;interests&quot; &#125; &#125; &#125;&#125;&apos;&#123; ... &quot;hits&quot;: &#123; ... &#125;, &quot;aggregations&quot;: &#123; &quot;all_interests&quot;: &#123; &quot;buckets&quot;: [ &#123; &quot;key&quot;: &quot;music&quot;, &quot;doc_count&quot;: 2 &#125;, &#123; &quot;key&quot;: &quot;forestry&quot;, &quot;doc_count&quot;: 1 &#125;, &#123; &quot;key&quot;: &quot;sports&quot;, &quot;doc_count&quot;: 1 &#125; ] &#125; &#125;&#125;]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[广告名词解释-Ad Network]]></title>
    <url>%2F2019%2F04%2F11%2F%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%2F%E5%B9%BF%E5%91%8A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A-Ad_Network%2F</url>
    <content type="text"><![CDATA[Ad Network 广告网络平台 1. 定义即“在线广告联盟”，是一种介于想出售广告空间的网站与想在网站上刊登广告的广告主之间的平台.(百度百科) 2. 运行机制最开始，Ad network 集合了众多的中小网站，汇集后即拥有了像是大平台的流量，甚至更多。因此开始有广告主愿意与 Ad network 购买广告，甚至原本拥有高流量的网站，因為有一些较少的版位沒有卖出，因此也加入了 Ad network。]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[广告名词解释-Ad Exchange]]></title>
    <url>%2F2019%2F04%2F10%2F%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%2F%E5%B9%BF%E5%91%8A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A-Ad_Exchange%2F</url>
    <content type="text"><![CDATA[Ad Exchange (广告交易平台) 1. 定义一个开放的、能够将出版商和广告商联系在一起的在线广告市场(类似于股票交易所)。(百度百科) 2. 运行机制当一个用户访问广告位页面时，ssp端向Ad Exchange发出访问讯号，告知有一个访问请求，ssp把广告位的具体信息，例如所属站点、最低出价以及通过DMP分析匹配后的用户属性信息打包发送给各个DSP，DSP端开始对这个广告展现进行竞价，竞价获胜者就能够让自己的广告展现在这个广告位上，进而让用户看到。 下图描述的例子是一个对汽车感兴趣的用户访问站点，DSP端各个汽车厂家对这个用户展开争夺的过程。]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[广告名词解释-DMP]]></title>
    <url>%2F2019%2F04%2F10%2F%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%2F%E5%B9%BF%E5%91%8A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A-DMP%2F</url>
    <content type="text"><![CDATA[DMP（Data-Management Platform，数据管理平台） 1. 定义是把分散的多方数据进行整合纳入统一的技术平台，并对这些数据进行标准化和细分，让用户可以把这些细分结果推向现有的互动营销环境里的平台。(百度百科) 2. 与DSP对比DSP 自己有可能有受众数据，但有很多其实没有，或者有，也不够全面，不够准确。那怎么办呢？专业提供者DMP出现了，简单讲，它们手中握有受众数据，并且能够让 DSP 驳接到他们这里，利用它们所有的数据。 DMP 为了获取受众的数据，它必须至少做几件事情：其一，它需要为所有的受众每一个做一个标记，这个标记在目前的技术条件下，主要是通过一种叫做 cookie 的事物完成的。其二，它还需要能够实现跨域追踪 DMP是本草纲目。DSP是专业药材买手。普通人对照着本草纲目也不大会买错药材，但对行情不熟悉，价钱高了低了没谱，找个专业买手付点服务费省心，说不定还省钱。买手逛的市场多了，慢慢的自己也有个小本本，记录不同时期好药材的成色等特点，比本草纲目要与时俱进一丁丁，但肯定没本草纲目记录的全。 查看大图 【扩展阅读】http://daily.zhihu.com/story/8700074?utm_campaign=in_app_share&amp;utm_medium=iOS&amp;utm_source=weixin]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[广告名词解释-SSP]]></title>
    <url>%2F2019%2F04%2F10%2F%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%2F%E5%B9%BF%E5%91%8A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A-SSP%2F</url>
    <content type="text"><![CDATA[SSP（Sell/Supply-Side Platform）供应方平台 1. 定义供应方平台能够让出版商也介入广告交易，从而使它们的库存广告可用。通过这一平台，出版商希望他们的库存广告可以获得最高的有效每千次展示费用，而不必以低价销售出去(百度百科) 通俗的讲：是站长服务平台，站长们在SSP上管理自己的广告位，控制广告的展现等。 2. 运行机制SSP与DSP是一一对应的。DSP负责管理广告媒体信息，以及广告媒体对应的用户属性。SSP负责供应广告媒体信息，根据站长提供的广告要求以及当前用户属性，上报到交易平台，最终敲定展示的广告信息，并返回到站长。 3. 特点 快速接入各种广告源、产品 快速验证广告的不同样式、调整广告页面布局 快速调整广告策略 精准的用户画像刻画 准确的广告推荐 分钟级数据监控 支持海量数据细粒度的多维数据查询 ####【扩展阅读】http://www.10tiao.com/html/488/201712/2247485109/1.html]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[广告名词解释-DSP]]></title>
    <url>%2F2019%2F04%2F10%2F%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%2F%E5%B9%BF%E5%91%8A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A-DSP%2F</url>
    <content type="text"><![CDATA[DSP（Demand-Side Platform）需求方平台 1. 定义需求方平台允许广告客户和广告机构更方便以及更有效地购买广告库存，因为该平台汇集了各种广告交易平台，广告网络，供应方平台，甚至媒体的库存。其实就是为甲方提供了跨媒介跨平台跨终端广告投放平台。(百度百科) 2. 运行机制从普通用户在浏览器中地址栏输入网站的网址，到用户看到页面上的内容和广告这短短几百毫秒之内，就需要发生了好几个网络往返(Round Trip)的信息交换。 Ad Exchange首先要向DSP发竞价(bidding)请求，告知DSP这次曝光的属性，如物料的尺寸、广告位出现的URL和类别、以及用户的Cookie ID等；DSP接到竞价请求后，也必须在几十毫秒之内决定是否竞价这次曝光, 如果决定竞价，出什么样的价格，然后把竞价的响应发回到Ad Exchange。 如果Ad Exchange判定该DSP赢得了该次竞价，要在极短时间内把DSP所代表的广告主的广告迅速送到用户的浏览器上。 DSP在整个过程中，通过运用人群定向技术分析，所得出的分析结果将直接影响广告主的广告投放效果。 3. 特点 能够整合、优化、管理不同渠道的流量 真正实现受众购买，拥有先进的用户定向(Audience Targeting)技术。 拥有强大的RTB(Real-Time Bidding)的基础设施和能力。 全面统一的数据报表 扩展阅读https://www.jianshu.com/p/0d14c0faf531?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[广告名词解释-RTB]]></title>
    <url>%2F2019%2F04%2F10%2F%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%2F%E5%B9%BF%E5%91%8A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A-RTB%2F</url>
    <content type="text"><![CDATA[RTB（Real Time Bidding）实时竞价 1. 定义一种利用第三方技术在数以百万计的网站上，针对每个用户展示行为进行评估以及出价的竞价技术(百度百科) 2. 运行机制四个主体角色：广告主（Advertiser）、DSP（DemandSidePlatform，需求方平台）、广告交易平台（Ad Exchange）、互联网媒体 整体运行机制：广告主将需求放到dsp平台上，互联网媒体将自己的广告流量资源放到广告交易平台，dsp通过与广告交易平台的技术对接完成竞价购买。 当用户访问网站时，浏览痕迹通过cookie记录，SSP即向Ad Exchange广告交易平台发送用户信息，随后广告位的具体信息则会经过DMP的分析匹配后发送给DSP，DSP将对此进行竞价，价高者会获得这个广告展现机会，并被目标用户看到 3. 特点精准营销、技术要求高]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Golang零基础入门】05 接口]]></title>
    <url>%2F2019%2F03%2F20%2FGolang%2F%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%2F05%20%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[什么是接口 接口是行为方法的抽象与概括 接口只有方法声明，不用和实现的细节绑定在一起，也没有数据字段 接口是隐式实现的，只要某个类型拥有该接口的所有方法，就算是接口实现，无需像其他语言里的implements显示声明 12345678910111213141516171819type action interface &#123; run()&#125;type cat struct &#123; name string&#125;func (c cat)run() &#123; fmt.Println("Run " + c.name)&#125;type dog struct &#123; name string&#125;func (d dog)run()&#123; fmt.Println("Run " + d.name)&#125; 嵌入接口我们上次说结构体的时候，已经说过结构体是能够嵌入的，接口也是可以嵌入的，例如animal嵌入了action、display接口 123456789101112131415161718192021222324type animal interface &#123; action display&#125;type action interface &#123; run()&#125;type display interface &#123; color() string&#125;type cat struct &#123; name string&#125;func (c cat)run() &#123; fmt.Println("Run " + c.name)&#125;func (c cat)color() string &#123; return "Grey"&#125; 类型断言断言类型的语法：x.(T)，这里x表示一个接口的类型，T表示一个类型（也可为接口类型）。一个类型断言检查一个接口对象x的动态类型是否和断言的类型T匹配。 如果类型比较少的话，可以用if ok pattern 1234567func assertCat(a animal) &#123; if catA, ok := a.(cat); ok &#123; fmt.Println("Animal : " + catA.name) return &#125; fmt.Println("Unknow")&#125; 如果类型较多的情况可以使用switch case 12345678func assertAnimal(a animal) &#123; switch v := a.(type) &#123; case cat: fmt.Println("Animal: " + v.name) default: fmt.Println("Unknown animal") &#125;&#125; 多态我们在实现多态的时候，可以直接做一层封装，接受接口的实例，这样便实现了类似抽象工厂模式 12345678910func animalRun(a animal) &#123; a.run()&#125;func main() &#123; catA := cat&#123;"cat"&#125; dogA := dog&#123;"dog"&#125; animalRun(catA) animalRun(dogA)&#125;]]></content>
      <categories>
        <category>Golang</category>
        <category>零基础入门</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Golang零基础入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Golang零基础入门】04 函数与方法]]></title>
    <url>%2F2019%2F03%2F19%2FGolang%2F%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%2F04%20%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[纯函数独立存在，不依附于任何实体，没有接收者 12345package helperfunc SayHi(name string) &#123; fmt.Printf("Hi %s", name)&#125; 方法与函数不一样的，在定义的时候，会与接收者绑定在一起。 123456789101112type human struct &#123; name string&#125;(h human)func SayHi() string &#123; return "Hi " + h.name&#125;func main()&#123; h := Human&#123;name:"lee"&#125; fmt.Println(h.SayHi())&#125; 与函数对比，应该可以看到，在函数func声明之前增加的（h human），这个就是接收者，每一个humman绑定了该方法，类似面向对象里的成员函数。 值接收&amp;指针接收 值接收者，在调用的时候是值接收者的一个副本，所以对该值的任何修改，不会影响原来的类型变量。 指针接收者传递的是一个指向原值指针的副本，所以修改时，同时也会影响原来类型变量的值。 123456789// 值接收，不能修改原值(h human)func set()&#123; h.name = "can not set"&#125;// 指针接收，能修改原值(h *human)func modify()&#123; h.nam = "can modify"&#125; 多值返回Go的函数方法支持多值返回，例如标准库中，很多都是返回两个值，一个是返回值，一个是出错时的错误信息，这就是我们经常看到下面这段代码的原因。 12345678if err != nil &#123; // do something&#125;// 我们定义方法func modify(name string)(string, error)&#123;return name, nil&#125;]]></content>
      <categories>
        <category>Golang</category>
        <category>零基础入门</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Golang零基础入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Golang零基础入门】03 数据类型]]></title>
    <url>%2F2019%2F03%2F19%2FGolang%2F%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%2F03%20%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[基本数据类型整型有符号类型：int8、int16、int32、int64，分别对应8、16、32、64bit大小 无符号类型：uint8、uint16、uint32、uint64 浮点数与复数float32和float64 两种精度的复数类型：complex64和complex128，分别对应float32和float64两种浮点数精度。 布尔型true和false 字符串只支持双引号，不支持单引号。string := &quot;hello, go&quot; 常量const 标记。 ioat常量生成器，适合生成枚举类型。如下面的例子，Sunday被声明为0，Monday为1，一次类推。 1234567891011type Weekday intconst ( Sunday Weekday = iota Monday Tuesday Wednesday Thursday Friday Saturday) 复合数据类型数组 array数组的长度是固定，所以实际项目中是比较少直接使用 123var num [10]int // 声明长度为10的int类型数组，每个值初始值为0var a [3]int = [3]int&#123;1, 2, 3&#125; // 声明时实例化var a = [...]int&#123;1, 2&#125; // 使用...数组的长度由初始化的个数决定，例如这长度为2 切片 slice变长的数组，如果你之前是写php，那你就可以把slice认为是php的无索引数组了,一般写作[]T 一个slice由三部分构成：指针、长度、容量。内置的len和cap函数返回对应长度和容量。len(s) == 0判断是否为空，不应该用 s == nil append扩展slice 12var nums []intnums = append(nums, 1, 2) 哈希表 map是一个无序的key/value对的集合，写法：map[K]V。 如果你之前是写php，那你可以把它认为是php的索引数组，但没有PHP灵活，他的key，必须是同一类型，value也必须是统一类型。 1234567891011121314151617181920212223242526score := make(map[string]int) // 创建key为string，value为int型// 初始化方法1score := map[string]int&#123; "lilei": 88, "hanmeimei": 90,&#125;// 初始化方法2score := make(map[string]int)score["lilei"] = 88score["hanmeimei"] = 90// 遍历for name, num := range score &#123; fmt.Printf("%s\t%d\n", name, num)&#125;// delete删除元素delete(ages, "li") // remove element ages["li"]// 小技巧，判断map中key是否存在// map的下标语法将产生两个值；第一个是值，第二个是一个布尔值，用于报告元素是否真的存在。if num, ok := score["xiaoming"]; ok &#123; //存在&#125; 结构体 struct复杂聚合数据类型。如果成员首字母大写，则对外可见。 12345type Student struct &#123; ID int Name string Age int&#125; 结构体嵌入和匿名成员 12345678910111213type Person struct &#123; Name, Addr string&#125;type Student struct &#123; Person Subject string&#125;var s students.Name = &quot;lilei&quot;s.Addr = &quot;beijing&quot;s.Subject = &quot;shuxue&quot; Go语言的特性：可以只声明一个成员对应的数据类型而不指定成员名，如上Person。实际项目中开发使用该声明方式。]]></content>
      <categories>
        <category>Golang</category>
        <category>零基础入门</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Golang零基础入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【MySQL 原理】01 体系结构]]></title>
    <url>%2F2019%2F03%2F07%2FMySQL%2FMySQL%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[MySQL体系结构–摘自MySQL官方手册 整体可分四层第一层：连接层防止资源的频繁分配、释放，提前建立一个连接池 功能：进行身份验证、线程管理、连接限制、内存检查、数据缓存。 实现：预先在连接池中放入一定数量的连接，当需要建立数据库连接时，从池中取出一个，用完放回去。 通信协议： TCP/IP协议，本地与远程连接 UNIX套接字文件 共享内存 命名管道 第二层：SQL层总共由5个部分组成 1. 管理服务和工具组件备份、复制、集群、管理、配置、迁移等管理工具 2. SQL接口组件进行DML、DDL，存储过程、视图等操作和管理 3. 解析器组件验证和解析SQL命令 4. 查询优化器对SQL查询进行优化 5. 缓存和缓冲区对结果集进行缓存，提升重复查询效率 第三层：插件式存储引擎MySQL的存储引擎是插件式的，能由第三方开发 – 查看数据库支持的引擎 3.1 MyISAM查询速度快，较好的索引优化和数据压缩技术，不支持事务、表锁设计，支持全文索引 MyISAM表由MYD和MYI组成，MYD存放数据数据，MYI存放索引文件 3.2 InnoDB支持事务，行锁设计、支持外键。 每个innodb存储引擎的表单独存放在独立的ibd文件中 3.3 Memory适合存储临时数据，如果数据库重启或崩溃，数据将消失。只支持表锁，并发性能差。 其他还有 Archive 、 Federated 、Maria存储引擎等 第四次：物理文件 支持的文件类型 EXT3、EXT4、NTFS、NFS 文件内容 数据文件 日志文件]]></content>
      <categories>
        <category>MySQL</category>
        <category>原理分析</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>原理分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Golang零基础入门】02 变量与类型]]></title>
    <url>%2F2019%2F03%2F06%2FGolang%2F%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%2F02%20%E7%B1%BB%E5%9E%8B%E4%B8%8E%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[可见性我们都知道其他面向对象的语言，都是用关键词public、private、protected来标记可见性。但在GO里，直接用首字母的大小写来决定可见性，大写对外可见，小写仅包内可见。例如fmt包的Printf函数在fmt包外部访问。 Golang习惯驼峰式命名，例如isExisits() 声明有四种类型的声明语句：变量var、常量const、类型type、函数func 变量1. var声明 var 变量名字 类型 = 表达式 一般 “类型”、或者“=”可以省略一个，例如： 12var i, j, k int // int, int, intvar b, f, s = true, 2.3, &quot;four&quot; // bool, float64, string 用处：用于需要显式指定变量类型地方，或者因为变量稍后会被重新赋值而初始值无关紧要的地方。 2. 简短声明 变量名字 := 表达式 1i := 100 用处：用于大部分的局部变量的声明和初始化。 注意，简短变量声明语句中必须至少要声明一个新的变量，下面的代码将不能编译通过： 123f, err := os.Open(infile)// ...f, err := os.Create(outfile) // 编译错误，提示没有新的变量，不需要:= 指针一个变量对应一个保存了变量对应类型值的内存空间。 一个指针的值是另一个变量的地址。 12345i := 1p := &amp;i // p 类型为 *int 指向ifmt.Println(*p) // "1"*p = 2 // 因为p指向了i的地址，所以相当于 i = 2fmt.Println(i) // "2" 类型类型声明语句一般出现在包一级，因此如果新创建的类型名字的首字符大写，则在外部包也可以使用。 type 类型名字 底层类型 例子：最常用的struct，User被声明为一个类型 1234type User struct&#123; name string age string&#125;]]></content>
      <categories>
        <category>Golang</category>
        <category>零基础入门</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Golang零基础入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Golang零基础入门】01 Hello，Go]]></title>
    <url>%2F2019%2F03%2F06%2FGolang%2F%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%2F01%20Hello%2C%20GO%2F</url>
    <content type="text"><![CDATA[一、第一个Go程序：hello.go1234567package mainimport "fmt"func main()&#123; fmt.Println("Hello, Go")&#125; 二、go run 一次性调试12$ go run hello.goHello, Go 说明： Go是一门编译型语言，Go语言的工具链将源代码及其依赖转换成计算机的机器指令。 go run 编译一个或多个以.go结尾的源文件，链接库文件，并运行最终生成的可执行文件。 三、go build 直接生成可执行程序如果不只是一次的调试，你可以编译这个程序，保存编译结果以备将来之用。可以用build子命令，将直接生成可执行文件 hello，之后直接运行hello可执行文件，结果与go run时是一致的： 123$ go build hello.go$ ./helloHello, GO 四、一些知识点 Go语言通过包（package）组织，类似其他语言的库、模块、命名空间。每个源文件都以一条 package 声明语句开始，这个例子里就是 package main main 包比较特殊。它定义了一个独立可执行的程序，而不是一个库。在 main 里的 main 函数也很特殊，它是整个程序执行时的入口 使用（import）来导入别的包，import &quot;fmt&quot; gofmt 工具把代码格式化为标准格式，最好在每次提交Git前执行一次，保证代码风格一致 go clean 移除当前源码包里编译生成的文件，如test.out 按照惯例，最好每个包的包声明前添加注释 12// package for app's configpackage config 空标识符（_下划线）类似垃圾箱，将不需要的变量丢弃，如下，只需要range的value，不需要索引 123for _, arg := range args &#123; // todo&#125;]]></content>
      <categories>
        <category>Golang</category>
        <category>零基础入门</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Golang零基础入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper 配置中心实现（Golang）]]></title>
    <url>%2F2019%2F03%2F02%2FZookeeper%2FZookeeper%20%E9%85%8D%E5%90%88Golang%E5%AE%9E%E7%8E%B0%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%2F</url>
    <content type="text"><![CDATA[目标一个乞丐版自更新配置中心，更新配置后，能在各个服务器实现更新 架构 角色 config-web: 配置后台，主要用于管理配置，增改配置 config-agent: 监听配置，遇到变动后，自动拉取最新文件到本地 config-sdk: 业务集成该sdk，用于读取配置 config-web 配置后台 持久存储为MySQL，也可以加一层缓存Redis，设置一个唯一的业务KEY，对应的ZK里的ZNode 对于配置节点的操作，最终必须落盘，持久化存储于MySQL 持久存储成功后，将配置的内容写入ZK集群中 以下是create节点的代码，set的同，这是简单的操作 123456789101112131415161718192021222324package mainimport ( &quot;fmt&quot; . &quot;go-zk/connect&quot; &quot;github.com/samuel/go-zookeeper/zk&quot;)func main() &#123; conn := Connect() defer conn.Close() flags := int32(zk.FlagSequence) acl := zk.WorldACL(zk.PermAll) // create node path := PathConfig.ZNodePath +&quot;/&quot;+ &quot;huodong-&quot; data := []byte(`&#123;&quot;num&quot;:6.13,&quot;strs&quot;:[&quot;a&quot;,&quot;b&quot;]&#125;`) createPath, err := conn.Create(path, data, flags, acl) if err != nil &#123; panic(err) &#125;&#125; config-agent 监控 由于ZK的特性，能保持集群的一致性，以及提供了监听机制，在节点内容被改变时能提供回调 在config-agent监听对应的业务节点 监听的变动时，会有通知，例如，更改节点内容时，获取节点的内容，然后进行落盘，或者存到内存中都 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129package mainimport ( &quot;fmt&quot; &quot;github.com/samuel/go-zookeeper/zk&quot; . &quot;go-zk/connect&quot; &quot;os&quot; &quot;sync&quot;)type Watch struct &#123;&#125;func (this *Watch)ZkChildrenWatch(c *zk.Conn, path string) &#123; for &#123; v, _, get_ch, err := c.ChildrenW(path) if err != nil &#123; fmt.Println(err) &#125; fmt.Printf(&quot;value of path[%s]=[%s].\n&quot;, path, v) for &#123; select &#123; case ch_event := &lt;-get_ch: &#123; fmt.Printf(&quot;%+v\n&quot;, ch_event) if ch_event.Type == zk.EventNodeCreated &#123; fmt.Printf(&quot;has new node[%d] create\n&quot;, ch_event.Path) &#125; else if ch_event.Type == zk.EventNodeDeleted &#123; fmt.Printf(&quot;has node[%s] detete\n&quot;, ch_event.Path) &#125; else if ch_event.Type == zk.EventNodeDataChanged &#123; this.Callback(c, ch_event.Path) &#125; else if ch_event.Type == zk.EventNodeChildrenChanged &#123; fmt.Printf(&quot;children node change%+v\n&quot;, ch_event.Path) &#125; &#125; &#125; break &#125; &#125;&#125;func (this *Watch)ZkNodeWatch(c *zk.Conn, path string) &#123; for &#123; v, _, get_ch, err := c.GetW(path) if err != nil &#123; fmt.Println(err) &#125; fmt.Printf(&quot;value of path[%s]=[%s].\n&quot;, path, v) for &#123; select &#123; case ch_event := &lt;-get_ch: &#123; if ch_event.Type == zk.EventNodeCreated &#123; fmt.Printf(&quot;has new node[%d] create\n&quot;, ch_event.Path) &#125; else if ch_event.Type == zk.EventNodeDeleted &#123; fmt.Printf(&quot;has node[%s] detete\n&quot;, ch_event.Path) &#125; else if ch_event.Type == zk.EventNodeDataChanged &#123; this.Callback(c, ch_event.Path) &#125; &#125; &#125; break &#125; &#125;&#125;func (this *Watch)Callback(c *zk.Conn, path string) &#123; data, _, err := c.Get(path) if err != nil &#123; fmt.Println(err) &#125; // create file fileName := PathConfig.LocalPath + path + &quot;.json&quot; os.Create(fileName) f, err := os.OpenFile(fileName, os.O_WRONLY|os.O_TRUNC, 0600) defer f.Close() if err != nil &#123; fmt.Println(err.Error()) &#125; else &#123; _,err=f.Write([]byte(data)) fmt.Println(err) return &#125; fmt.Print(&quot;Write File OK !!!&quot;)&#125;func main() &#123; conn := Connect() // 监听所有子节点变化 children, _, err := conn.Children(PathConfig.ZNodePath) if err != nil &#123; panic(err) &#125; fmt.Printf(&quot;%+v\n&quot;, children) w := Watch&#123;&#125; var wg sync.WaitGroup wg.Add(1) go func(path string) &#123; w.ZkChildrenWatch(conn, path) &#125;(PathConfig.ZNodePath) wg.Wait() // 监听节点内容变化 //var wg sync.WaitGroup //wg.Add(len(children)) // //for _, path := range children&#123; // path = PathConfig.ZNodePath + &quot;/&quot; + path // go func(path string) &#123; // defer wg.Done() // log.Print(&quot;Zookeeper Watcher Starting, &quot;, path) // w.ZkNodeWatch(conn, path) // &#125;(path) //&#125; //wg.Wait()&#125; config-sdk 客户端加载配置读取配置的方式很多样，两种思路： 直接读取文件，由业务方直接读取，.json 、 .ini 、 .toml等 sdk可以与config-agent结合，如果读取文件加载配置失败，利用agent，重新主动拉一次文件到本地，实现文件的懒加载 效果展示12345678910111213# This is Zookeeper config file.title = &quot;Zookeeper config file&quot;[zookeeper]servers = [&quot;10.00.85.70:2181&quot;, &quot;10.00.80.191:2181&quot;, &quot;10.00.97.239:2181&quot;]port = 2181session_timeout = 500enabled = true[path]znode_path = &quot;/huodong/conf&quot;local_path = &quot;/tmp/zookeeper&quot; 由于在本地测试，嫌麻烦就没有部署到服务器了，将locah_path分别改成”/tmp/zookeeper”、”/tmp/zookeeper1”、”/tmp/zookeeper2”，起三个进程 连接到zk服务器，修改节点的内容set /huodong/conf/huodong-0000000001 &#39;{&quot;num&quot;:6.13,&quot;strs&quot;:[&quot;a&quot;,&quot;b&quot;]}&#39; 看下本地文件就会生成对应的配置文件]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper 集群搭建]]></title>
    <url>%2F2019%2F02%2F28%2FZookeeper%2FZookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[目标用三台机器搭建一个Zookeeper集群 新增myid文件用于配置当前IP对应的编号。可以查看/conf/zoo.cfg的dataDir路径，在该路径新增myid，内容就只协商对应的编号就行 12$ cat /tmp/zookeeper/myid1 编辑配置文件vi /conf/zoo.cfg 在该配置文件下新增以下内容，每个服务器都需要增加 123server.1=10.99.85.70:2888:3888server.2=10.99.80.191:2888:3888server.3=10.99.97.239:2888:3888 说明：server.A=B:C:D A 是一个数字，就是myid里的那个数字，表示这个是第几号服务器 B 是这个服务器的 ip 地址 C 用来集群成员的信息交换以及与集群中的 Leader 服务器交换信息 D 端口是在leader挂掉时专门用来进行选举Leader所用。 逐一启动服务12345678910111213141516171819$ bin/zkServer.sh start#ip 1$ bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /zookeeper-3.4.8/bin/../conf/zoo.cfgMode: follower#ip 2$ bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /zookeeper-3.4.8/bin/../conf/zoo.cfgMode: leader# ip 3$ bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /zookeeper-3.4.8/bin/../conf/zoo.cfgMode: follower Leader选举情况步骤一：启动服务器1时，投票给自己，服务器1获得了1票，没达到半数 步骤二： 启动服务器2时，投票给自己，服务器2获得1票，没达到半数； 服务器1与2都是1票，重新发起投票； 2的服务器ID大于1，1会重新投票给2，2还是仍然投票给自己 服务器2获得了2票，达到半数，当选Leader]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka 入门介绍]]></title>
    <url>%2F2019%2F02%2F27%2FKafka%2FKafka%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[下一个最大元素 I]]></title>
    <url>%2F2019%2F02%2F26%2F%E6%AF%8F%E6%97%A5%E4%B8%80%E7%AE%97%2F%E4%B8%8B%E4%B8%80%E4%B8%AA%E6%9B%B4%E5%A4%A7%E5%85%83%E7%B4%A0%20I%2F</url>
    <content type="text"><![CDATA[题源LeetCode题目：https://leetcode-cn.com/problems/next-greater-element-i/ 给定两个没有重复元素的数组 nums1 和 nums2 ，其中nums1 是 nums2 的子集。找到 nums1 中每个元素在 nums2 中的下一个比其大的值。 nums1 中数字 x 的下一个更大元素是指 x 在 nums2 中对应位置的右边的第一个比 x 大的元素。如果不存在，对应位置输出-1。 示例 1: 输入: nums1 = [4,1,2], nums2 = [1,3,4,2].输出: [-1,3,-1]解释: 对于num1中的数字4，你无法在第二个数组中找到下一个更大的数字，因此输出 -1。 对于num1中的数字1，第二个数组中数字1右边的下一个较大数字是 3。 对于num1中的数字2，第二个数组中没有下一个更大的数字，因此输出 -1。 nums1和nums2中所有元素是唯一的。nums1和nums2 的数组大小都不超过1000。 解法关键词：单调栈 循环遍历较长的数组组成单调递减栈 当栈顶小于当前元素时，出栈，存储到数组或hashmap中 循环较短的数组，查找是否在hashmap中 源码1234567891011121314151617181920212223242526272829303132333435&lt;?phpclass Solution &#123; /** * @param Integer[] $nums1 * @param Integer[] $nums2 * @return Integer[] */ function nextGreaterElement($nums1, $nums2) &#123; $hashMap = []; $stack = []; foreach ($nums2 as $value) &#123; while (!empty($stack) &amp;&amp; end($stack) &lt; $value) &#123; $hashMap[array_pop($stack)]=$value; &#125; array_push($stack, $value); &#125; $res = []; foreach ($nums1 as $value) &#123; if (isset($hashMap[$value])) &#123; $res[] = $hashMap[$value]; &#125; else &#123; $res[] = -1; &#125; &#125; return $res; &#125;&#125;$s = new Solution();$res = $s-&gt;nextGreaterElement([1,3,5,2,4],[6,5,4,3,2,1,7]);var_dump($res);]]></content>
      <categories>
        <category>每日一算</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper 面试题]]></title>
    <url>%2F2019%2F02%2F25%2F%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2%2FZookeeper%E9%9D%A2%E8%AF%95%2F</url>
    <content type="text"><![CDATA[1. Zookeeper的用途，选举的原理是什么？用途 分布式锁 服务注册和发现 利用Znode和Watcher，可以实现分布式服务的注册和发现。最著名的应用就是阿里的分布式RPC框架Dubbo。 共享配置和状态信息 Redis的分布式解决方案Codis（豌豆荚），就利用了Zookeeper来存放数据路由表和 codis-proxy 节点的元信息。同时 codis-config 发起的命令都会通过 ZooKeeper 同步到各个存活的 codis-proxy。 软负载均衡 选举原理 每个 server 发出一个投票： 投票的最基本元素是（SID-服务器id,ZXID-事物id） 接受来自各个服务器的投票 处理投票：优先检查 ZXID(数据越新ZXID越大),ZXID比较大的作为leader，ZXID一样的情况下比较SID 统计投票：这里有个过半的概念，大于集群机器数量的一半，即大于或等于（n/2+1）,我们这里的由三台，大于等于2即为达到“过半”的要求。这里也有引申到为什么 Zookeeper 集群推荐是单数。 2. zookeeper watch机制 客户端 服务端 Main进程 创建ZK客户端，会创建connet网络连接通信线程，listener监听线程 通过connect线程将注册的监听事件发送给Zookeeper服务端 将监听事件添加到注册监听器列表 监听到有数据或路径变化，将消息发送给listener listener线程内部调用process方法 3. Zookeeper 分布式锁]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper 入门介绍]]></title>
    <url>%2F2019%2F02%2F25%2FZookeeper%2FZookeeper%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[一、什么是ZookeeperZooKeeper是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 它的核心是：文件系统 + 通知机制 二、重要特点 一个领导者(Leader)，多个跟随者(Follower)组成的集群 集群中只要有半数以上节点存活，Zookeeper集群就能正常服务 全局数据一致性，每个server保存一份相同的副本，client无论链接哪个server，得到的数据都是一致的 更新请求顺序执行，来自同一个client的请求按顺序执行 数据更新原子性，一次数据更新要么成功要么失败 实时性，在一定时间范围内，client能读到最新数据 三、数据结构Zookeeper数据模型的结构与Unix文件系统很类似，整体上可看作是一棵树，每个节点称作一个ZNode。每个ZNode默认能存储1MB数据，每个ZNode都可以通过其路径唯一标识。 四、应用场景(※) 分布式锁 服务注册和发现 利用Znode和Watcher，可以实现分布式服务的注册和发现。最著名的应用就是阿里的分布式RPC框架Dubbo。 共享配置和状态信息 Redis的分布式解决方案Codis（豌豆荚），就利用了Zookeeper来存放数据路由表和 codis-proxy 节点的元信息。同时 codis-config 发起的命令都会通过 ZooKeeper 同步到各个存活的 codis-proxy。 五、选举机制(※)5.1 半数机制（paxos协议）集群中半数以上机器存活，集群可用，所以Zookeeper适合安装奇数台服务器 5.2 内部选举在分布式系统中选主最直接的方法是直接选定集群的一个节点为leader，其它的节点为follower，这样引入的一个问题是如果leader节点挂掉，整个集群就挂掉了。需要有一种算法自动选主，如果leader节点挂掉，则从follower节点中选出一个主节点。 1. 选举阶段 Leader election 最大ZXID也就是节点本地的最新事务编号，包含epoch和计数两部分。epoch是纪元的意思，相当于Raft算法选主时候的term，标识当前leader周期，每次选举一个新的Leader服务器后，会生成一个新的epoch 所有节点处于Looking状态，各自依次发起投票，投票包含自己的服务器ID和最新事务ID（ZXID）。 如果发现别人的ZXID比自己大，也就是数据比自己新，那么就重新发起投票，投票给目前已知最大的ZXID所属节点。 每次投票后，服务器都会统计投票数量，判断是否有某个节点得到半数以上的投票。如果存在这样的节点，该节点将会成为准Leader，状态变为Leading。其他节点的状态变为Following。 2. 发现阶段 Discovery 为了防止某些意外情况，比如因网络原因在上一阶段产生多个Leader的情况。 Leader集思广益，接收所有Follower发来各自的最新epoch值。Leader从中选出最大的epoch，基于此值加1，生成新的epoch分发给各个Follower。 各个Follower收到全新的epoch后，返回ACK给Leader，带上各自最大的ZXID和历史事务日志。Leader选出最大的ZXID，并更新自身历史日志。 3. 同步阶段 Synchronization Leader刚才收集得到的最新历史事务日志，同步给集群中所有的Follower。只有当半数Follower同步成功，这个准Leader才能成为正式的Leader。 六、ZNode 内构6.1 节点类型持久persistent：client 和 server 断开连接后，创建的节点不删除 短暂ephemeral：client 和 server 断开连接后，创建的节点自己删除 另外分 有序和无序。创建有序节点时，会自动将节点名增加序列号 12$ create -s /test/no1 &quot;no1&quot;Created /test/no10000000000 6.2 内部结构 data: ZNode存储的数据信息，每个节点数据最大不超过1MB ACL(Access Control List): 记录访问权限，哪些人或哪些IP可访问本节点 child: 当前节点的子节点 stat: 各种元数据，比如事务ID、版本号、时间戳、大小等 czxid- 引起这个 znode 创建的 zxid，创建节点的事务的 zxid ctime - znode 被创建的毫秒数 mzxid - znode 最后更新的 zxid mtime - znode 最后修改的毫秒数 pZxid-znode 最后更新的子节点 zxid cversion - znode 子节点变化号，znode 子节点修改次数 7)dataversion - znode 数据变化号 aclVersion - znode 访问控制列表的变化号 ephemeralOwner- 如果是临时节点，这个是znode拥有者的 session id。如果不是临时节点则是 0 dataLength- znode 的数据长度 numChildren - znode 子节点数量 七、监听器原理(※) 客户端 服务端 Main进程 创建ZK客户端，会创建connet网络连接通信线程，listener监听线程 通过connect线程将注册的监听事件发送给Zookeeper服务端 将监听事件添加到注册监听器列表 监听到有数据或路径变化，将消息发送给listener listener线程内部调用process方法 八、常见监听 子节点增减变化（如下示例） 节点数据变化 九、写数据流程 客户端发出写入数据请求给任意Follower。 Follower把写入数据请求转发给Leader。 Leader采用二阶段提交方式，先发送Propose广播给Follower。 Follower接到Propose消息，写入日志成功后，返回ACK消息给Leader。 Leader接到半数以上ACK消息，返回成功给客户端，并且广播Commit请求给Follower 十、命令客户端连接 zkcli -server host:port create [-s] [-e] path data acl 12$ create /test "data"Created /test get path [watch] watch指是否监听 12345678910111213[zk: 10.96.86.22:2181(CONNECTED) 10] get /testdatacZxid = 0x10ctime = Mon Feb 25 16:34:23 CST 2019mZxid = 0x10mtime = Mon Feb 25 16:34:23 CST 2019pZxid = 0x10cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 4numChildren = 0 更多stat path [watch]set path data [version]ls path [watch]delquota [-n|-b] pathls2 path [watch]setAcl path aclsetquota -n|-b val pathhistoryredo cmdnoprintwatches on|offdelete path [version]sync pathlistquota pathrmr pathaddauth scheme authquitgetAcl pathcloseconnect host:port 参考https://juejin.im/post/5b037d5c518825426e024473https://www.bilibili.com/video/av32093417/https://blog.csdn.net/u013679744/article/details/79222103《从Paxos到ZooKeeper》经典]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务端面试题集（补充）]]></title>
    <url>%2F2019%2F02%2F25%2F%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2%2F%E6%9C%8D%E5%8A%A1%E7%AB%AF%E9%9D%A2%E8%AF%95%E8%A1%A5%E5%85%85%2F</url>
    <content type="text"><![CDATA[来源声明来源网络 补充上篇 mysql事务隔离级别，脏读 mysql索引 B+数 kafka怎么避免重复消费 kafka怎么保证顺序消费 kafka分区有什么用 消费者宕机了，怎么确认有没收到消息 消费者group订阅了一个topic，当topic接收到消息时，消费者group上的所有消费者能接收到消息吗 thrift协议与http协议的区别 golang垃圾回收算法、PHP垃圾回收算法 rpc与http和thrift关系]]></content>
      <categories>
        <category>每日一面</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务端面试题集]]></title>
    <url>%2F2019%2F02%2F23%2F%E6%AF%8F%E6%97%A5%E4%B8%80%E9%9D%A2%2F%E6%9C%8D%E5%8A%A1%E7%AB%AF%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%88%E6%B1%87%E6%80%BB%EF%BC%89%2F</url>
    <content type="text"><![CDATA[来源声明从GitHub找到的java面试题集，涵盖的内容比较全，这里仅摘了通用的部分，与语言无关。 GitHub地址 分布式相关 对分布式事务的理解 如何实现负载均衡，有哪些算法可以实现？ Zookeeper的用途，选举的原理是什么？ 数据的垂直拆分水平拆分。 zookeeper watch机制 redis/zk节点宕机如何处理 分布式集群下如何做到唯一序列号 如何做一个分布式锁 用过哪些MQ，怎么用的，和其他mq比较有什么优缺点，MQ的连接是线程安全的吗 MQ系统的数据如何保证不丢失 列举出你能想到的数据库分库分表策略；分库分表后，如何解决全表查询的问题。 算法&amp;数据结构&amp;设计模式 海量url去重类问题（布隆过滤器） 数组和链表数据结构描述，各自的时间复杂度 二叉树遍历 快速排序 BTree相关的操作 在工作中遇到过哪些设计模式，是如何应用的 hash算法的有哪几种，优缺点，使用场景 什么是一致性hash paxos算法 在装饰器模式和代理模式之间，你如何抉择，请结合自身实际情况聊聊 代码重构的步骤和原因，如果理解重构到模式？ 数据库 MySQL InnoDB存储的文件结构 索引树是如何维护的？ 数据库自增主键可能的问题 MySQL的几种优化 mysql索引为什么使用B+树 数据库锁表的相关处理 索引失效场景 高并发下如何做到安全的修改同一行数据，乐观锁和悲观锁是什么，INNODB的行级锁有哪2种，解释其含义 数据库会死锁吗，举一个死锁的例子，mysql怎么解决死锁 Redis&amp;缓存相关 Redis的并发竞争问题如何解决了解Redis事务的CAS操作吗 缓存机器增删如何对系统影响最小，一致性哈希的实现 Redis持久化的几种方式，优缺点是什么，怎么实现的 Redis的缓存失效策略 缓存穿透的解决办法 redis集群，高可用，原理 mySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据 用Redis和任意语言实现一段恶意登录保护的代码，限制1小时内每用户Id最多只能登录5次 redis的数据淘汰策略 网络相关 http1.0和http1.1有什么区别 http和https有什么区别 TCP/IP协议 TCP三次握手和四次挥手的流程，为什么断开连接要4次,如果握手只有两次，会出现什么 TIME_WAIT和CLOSE_WAIT的区别 说说你知道的几种HTTP响应码 当你用浏览器打开一个链接的时候，计算机做了哪些工作步骤 TCP/IP如何保证可靠性，数据包有哪些数据组成 长连接与短连接 Http请求get和post的区别以及数据包格式 简述tcp建立连接3次握手，和断开连接4次握手的过程；关闭连接时，出现TIMEWAIT过多是由什么原因引起，是出现在主动断开方还是被动断开方。 其他 Linux下IO模型有几种，各自的含义是什么 实际场景问题，海量登录日志如何排序和处理SQL操作，主要是索引和聚合函数的应用 实际场景问题解决，典型的TOP K问题 线上bug处理流程 如何从线上日志发现问题 linux利用哪些命令，查找哪里出了问题（例如io密集任务，cpu过度） 场景问题，有一个第三方接口，有很多个线程去调用获取数据，现在规定每秒钟最多有10个线程同时调用它，如何做到。 用三个线程按顺序循环打印abc三个字母，比如abcabcabc。 常见的缓存策略有哪些，你们项目中用到了什么缓存系统，如何设计的 设计一个秒杀系统，30分钟没付款就自动关闭交易（并发会很高） 请列出你所了解的性能测试工具 后台系统怎么防止请求重复提交？ 有多个相同的接口，我想客户端同时请求，然后只需要在第一个请求返回结果的时候返回给客户端 PHP相关 php-fpm运行原理]]></content>
      <categories>
        <category>每日一面</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis读书笔记一：简单动态字符串]]></title>
    <url>%2F2019%2F02%2F23%2FRedis%2F%E7%AE%80%E5%8D%95%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[简单动态字符串 结构12345678struct sdshdr &#123; // 记录已使用字节的数量 long len; // 记录未使用的字节数量 long free; // 保存字符串 char buf[];&#125;; buf以&#39;\0&#39;为作为字符串结束符，为了能使用C语言本身的库 SDS设计对比C语言字符串的优势： 获取字符串长度的时间复杂度 O(1) 避免缓冲区溢出情况 在拼接扩展字符串时，先检测free是否有足够的容量加载新字符，无则新分配内存 减少修改字符串带来的内存重新分配次数： 空间预分配：在做空间扩展时，不仅会分配必须的内存大小，还会额外分配未使用空间。额外分配规则： 如果分配后，sds-&gt;len大小小于1M，将分配额外空间大小为sds-&gt;len。例如：修改后len大小为13，则会分配free=13，最终buf的字节长度为 13(len)+13(fee)+1(&#39;\0&#39;) = 27; 如果分配后，sds-&gt;len大小 大于 1M，将分配额外空间大小为1M。例如，修改后len大小为30M，则会分配free=1M，最终buf的字节长度为 30M + 1M +1byte 惰性空间释放 避免内存重新分配 为将来可能有的增长操作提供了优化 二进制安全 在C语言中，如果存在&#39;\0&#39;，则会终止取值。二进制的内容可能存在该字符，所以在C语言中是不安全的，但sds是根据len取值 兼容部分 C 字符串函数。]]></content>
      <categories>
        <category>Redis</category>
        <category>《Redis设计与实现》读书笔记</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
</search>
